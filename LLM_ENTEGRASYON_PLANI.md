# LLM Entegrasyon PlanÄ±

## ğŸ¯ YapÄ±lacaklar

### 1. **LLM SaÄŸlayÄ±cÄ± SeÃ§imi**
   - **Ã–nerilen: Groq API** (Ãœcretsiz tier, hÄ±zlÄ±, Llama 3 modeli)
   - Alternatifler: OpenAI, Hugging Face, Local Model

### 2. **Kurulum AdÄ±mlarÄ±**

#### A. Backend Paketleri Ekleme
   - `@nestjs/config` - Environment variable yÃ¶netimi
   - `groq-sdk` - Groq API client (veya `openai` OpenAI iÃ§in)

#### B. Environment Variables
   - `.env` dosyasÄ±na `GROQ_API_KEY` ekleme
   - API key'i [Groq Console](https://console.groq.com/)'dan alÄ±nÄ±r

#### C. LLM Servisi GÃ¼ncelleme
   - `llm.service.ts` dosyasÄ±nÄ± gÃ¼ncelleme
   - GerÃ§ek API Ã§aÄŸrÄ±larÄ± ekleme
   - Prompt engineering (rubrik tabanlÄ± JSON Ã§Ä±ktÄ±)

### 3. **Prompt TasarÄ±mÄ±**
   - Rubrik kriterlerine gÃ¶re deÄŸerlendirme
   - JSON format Ã§Ä±ktÄ± (structured output)
   - TÃ¼rkÃ§e geri bildirim Ã¼retimi

### 4. **Hata YÃ¶netimi**
   - API hatalarÄ±nda mock mode'a fallback
   - Retry mekanizmasÄ±

## ğŸ“ Teknik Detaylar

### Groq API Ã–zellikleri
- Model: `llama-3.1-70b-versatile` veya `llama-3.3-70b-versatile`
- HÄ±z: ~300 tokens/saniye
- Ãœcretsiz Tier: GÃ¼nde 30 request (14,400 requests/day)
- JSON Mode desteÄŸi var

### Prompt YapÄ±sÄ±
```typescript
const prompt = `
Sen bir eÄŸitim uzmanÄ±sÄ±n. AÅŸaÄŸÄ±daki aÃ§Ä±k uÃ§lu soruyu ve Ã¶ÄŸrenci yanÄ±tÄ±nÄ± deÄŸerlendir.

SORU: ${question}
Ã–ÄRENCÄ° YANITI: ${answer}

AÅŸaÄŸÄ±daki kriterlere gÃ¶re deÄŸerlendirme yap:
1. DoÄŸruluk (AÄŸÄ±rlÄ±k: %40): YanÄ±tÄ±n soruya uygunluÄŸu ve bilimsel doÄŸruluÄŸu
2. Kapsam (AÄŸÄ±rlÄ±k: %35): Konuyu kapsama dÃ¼zeyi ve derinliÄŸi
3. Netlik (AÄŸÄ±rlÄ±k: %25): Ä°fade aÃ§Ä±klÄ±ÄŸÄ± ve mantÄ±ksal tutarlÄ±lÄ±k

JSON formatÄ±nda cevap ver:
{
  "accuracy": { "score": 0-100, "feedback": "aÃ§Ä±klama" },
  "coverage": { "score": 0-100, "feedback": "aÃ§Ä±klama" },
  "clarity": { "score": 0-100, "feedback": "aÃ§Ä±klama" },
  "totalScore": 0-100,
  "overallFeedback": "genel deÄŸerlendirme"
}
`;
```

## âš ï¸ Dikkat Edilmesi Gerekenler

1. **API Rate Limits**: Groq'un rate limit'lerine dikkat
2. **Maliyet**: Groq Ã¼cretsiz tier var ama kontrol edin
3. **Response Time**: LLM Ã§aÄŸrÄ±sÄ± 2-5 saniye sÃ¼rebilir
4. **Error Handling**: API hatalarÄ±nda fallback mekanizmasÄ±
5. **Token Limit**: Prompt + response token limit'lerini kontrol edin

## ğŸ”„ Mock Mode vs Real LLM

- API key yoksa â†’ Mock mode
- API key varsa â†’ GerÃ§ek LLM kullan
- API hatasÄ± olursa â†’ Mock mode'a fallback





